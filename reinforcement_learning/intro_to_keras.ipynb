{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
      "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
      "features.shape: (284807, 30)\n",
      "targets.shape: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# Get the real data from https://www.kaggle.com/mlg-ulb/creditcardfraud/\n",
    "fname = \"creditcard.csv\"\n",
    "\n",
    "all_features = []\n",
    "all_targets = []\n",
    "with open(fname) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            print(\"HEADER:\", line.strip())\n",
    "            continue  # Skip header\n",
    "        fields = line.strip().split(\",\")\n",
    "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
    "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
    "        if i == 1:\n",
    "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
    "\n",
    "features = np.array(all_features, dtype=\"float32\")\n",
    "targets = np.array(all_targets, dtype=\"uint8\")\n",
    "print(\"features.shape:\", features.shape)\n",
    "print(\"targets.shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 227846\n",
      "Number of validation samples: 56961\n"
     ]
    }
   ],
   "source": [
    "num_val_samples = int(len(features) * 0.2)\n",
    "train_features = features[:-num_val_samples]\n",
    "train_targets = targets[:-num_val_samples]\n",
    "val_features = features[-num_val_samples:]\n",
    "val_targets = targets[-num_val_samples:]\n",
    "\n",
    "print(\"Number of training samples:\", len(train_features))\n",
    "print(\"Number of validation samples:\", len(val_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in training data: 417 (0.18% of total)\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(train_targets[:, 0])\n",
    "print(\n",
    "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
    "    )\n",
    ")\n",
    "\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_features, axis=0)\n",
    "train_features -= mean\n",
    "val_features -= mean\n",
    "std = np.std(train_features, axis=0)\n",
    "train_features /= std\n",
    "val_features /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               7936      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 139,777\n",
      "Trainable params: 139,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            256, activation=\"relu\", input_shape=(train_features.shape[-1],)\n",
    "        ),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaca1\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py:523: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "C:\\Users\\vaca1\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py:1389: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  if isinstance(sample_weight_mode, collections.Mapping):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 227846 samples, validate on 56961 samples\n",
      "Epoch 1/30\n",
      "227846/227846 - 6s - loss: 2.2489e-06 - fn: 48.0000 - fp: 25108.0000 - tn: 202321.0000 - tp: 369.0000 - precision: 0.0145 - recall: 0.8849 - val_loss: 1.5033e-06 - val_fn: 4.0000 - val_fp: 4643.0000 - val_tn: 52243.0000 - val_tp: 71.0000 - val_precision: 0.0151 - val_recall: 0.9467\n",
      "Epoch 2/30\n",
      "227846/227846 - 3s - loss: 1.6534e-06 - fn: 37.0000 - fp: 8131.0000 - tn: 219298.0000 - tp: 380.0000 - precision: 0.0446 - recall: 0.9113 - val_loss: 1.3702e-06 - val_fn: 12.0000 - val_fp: 205.0000 - val_tn: 56681.0000 - val_tp: 63.0000 - val_precision: 0.2351 - val_recall: 0.8400\n",
      "Epoch 3/30\n",
      "227846/227846 - 3s - loss: 1.2621e-06 - fn: 28.0000 - fp: 7480.0000 - tn: 219949.0000 - tp: 389.0000 - precision: 0.0494 - recall: 0.9329 - val_loss: 1.0130e-06 - val_fn: 10.0000 - val_fp: 373.0000 - val_tn: 56513.0000 - val_tp: 65.0000 - val_precision: 0.1484 - val_recall: 0.8667\n",
      "Epoch 4/30\n",
      "227846/227846 - 4s - loss: 1.0812e-06 - fn: 27.0000 - fp: 6914.0000 - tn: 220515.0000 - tp: 390.0000 - precision: 0.0534 - recall: 0.9353 - val_loss: 1.1688e-06 - val_fn: 5.0000 - val_fp: 3033.0000 - val_tn: 53853.0000 - val_tp: 70.0000 - val_precision: 0.0226 - val_recall: 0.9333\n",
      "Epoch 5/30\n",
      "227846/227846 - 3s - loss: 1.0266e-06 - fn: 20.0000 - fp: 7144.0000 - tn: 220285.0000 - tp: 397.0000 - precision: 0.0526 - recall: 0.9520 - val_loss: 1.0649e-06 - val_fn: 3.0000 - val_fp: 4208.0000 - val_tn: 52678.0000 - val_tp: 72.0000 - val_precision: 0.0168 - val_recall: 0.9600\n",
      "Epoch 6/30\n",
      "227846/227846 - 3s - loss: 1.1583e-06 - fn: 24.0000 - fp: 9316.0000 - tn: 218113.0000 - tp: 393.0000 - precision: 0.0405 - recall: 0.9424 - val_loss: 1.0259e-06 - val_fn: 7.0000 - val_fp: 2089.0000 - val_tn: 54797.0000 - val_tp: 68.0000 - val_precision: 0.0315 - val_recall: 0.9067\n",
      "Epoch 7/30\n",
      "227846/227846 - 3s - loss: 8.2092e-07 - fn: 17.0000 - fp: 6644.0000 - tn: 220785.0000 - tp: 400.0000 - precision: 0.0568 - recall: 0.9592 - val_loss: 1.2946e-06 - val_fn: 7.0000 - val_fp: 595.0000 - val_tn: 56291.0000 - val_tp: 68.0000 - val_precision: 0.1026 - val_recall: 0.9067\n",
      "Epoch 8/30\n",
      "227846/227846 - 3s - loss: 6.3220e-07 - fn: 13.0000 - fp: 6619.0000 - tn: 220810.0000 - tp: 404.0000 - precision: 0.0575 - recall: 0.9688 - val_loss: 1.2863e-06 - val_fn: 7.0000 - val_fp: 1184.0000 - val_tn: 55702.0000 - val_tp: 68.0000 - val_precision: 0.0543 - val_recall: 0.9067\n",
      "Epoch 9/30\n",
      "227846/227846 - 3s - loss: 4.7316e-07 - fn: 7.0000 - fp: 5499.0000 - tn: 221930.0000 - tp: 410.0000 - precision: 0.0694 - recall: 0.9832 - val_loss: 1.9052e-06 - val_fn: 10.0000 - val_fp: 639.0000 - val_tn: 56247.0000 - val_tp: 65.0000 - val_precision: 0.0923 - val_recall: 0.8667\n",
      "Epoch 10/30\n",
      "227846/227846 - 3s - loss: 5.3204e-07 - fn: 9.0000 - fp: 6137.0000 - tn: 221292.0000 - tp: 408.0000 - precision: 0.0623 - recall: 0.9784 - val_loss: 2.3600e-06 - val_fn: 8.0000 - val_fp: 536.0000 - val_tn: 56350.0000 - val_tp: 67.0000 - val_precision: 0.1111 - val_recall: 0.8933\n",
      "Epoch 11/30\n",
      "227846/227846 - 3s - loss: 5.7788e-07 - fn: 10.0000 - fp: 6959.0000 - tn: 220470.0000 - tp: 407.0000 - precision: 0.0553 - recall: 0.9760 - val_loss: 9.6197e-07 - val_fn: 6.0000 - val_fp: 2896.0000 - val_tn: 53990.0000 - val_tp: 69.0000 - val_precision: 0.0233 - val_recall: 0.9200\n",
      "Epoch 12/30\n",
      "227846/227846 - 3s - loss: 5.3131e-07 - fn: 7.0000 - fp: 6383.0000 - tn: 221046.0000 - tp: 410.0000 - precision: 0.0604 - recall: 0.9832 - val_loss: 1.8226e-06 - val_fn: 7.0000 - val_fp: 811.0000 - val_tn: 56075.0000 - val_tp: 68.0000 - val_precision: 0.0774 - val_recall: 0.9067\n",
      "Epoch 13/30\n",
      "227846/227846 - 3s - loss: 5.9365e-07 - fn: 9.0000 - fp: 8069.0000 - tn: 219360.0000 - tp: 408.0000 - precision: 0.0481 - recall: 0.9784 - val_loss: 1.7271e-06 - val_fn: 8.0000 - val_fp: 1217.0000 - val_tn: 55669.0000 - val_tp: 67.0000 - val_precision: 0.0522 - val_recall: 0.8933\n",
      "Epoch 14/30\n",
      "227846/227846 - 3s - loss: 5.2519e-07 - fn: 7.0000 - fp: 6197.0000 - tn: 221232.0000 - tp: 410.0000 - precision: 0.0621 - recall: 0.9832 - val_loss: 1.5282e-06 - val_fn: 7.0000 - val_fp: 908.0000 - val_tn: 55978.0000 - val_tp: 68.0000 - val_precision: 0.0697 - val_recall: 0.9067\n",
      "Epoch 15/30\n",
      "227846/227846 - 3s - loss: 4.0043e-07 - fn: 5.0000 - fp: 4281.0000 - tn: 223148.0000 - tp: 412.0000 - precision: 0.0878 - recall: 0.9880 - val_loss: 3.1490e-06 - val_fn: 9.0000 - val_fp: 350.0000 - val_tn: 56536.0000 - val_tp: 66.0000 - val_precision: 0.1587 - val_recall: 0.8800\n",
      "Epoch 16/30\n",
      "227846/227846 - 3s - loss: 5.2151e-07 - fn: 5.0000 - fp: 6557.0000 - tn: 220872.0000 - tp: 412.0000 - precision: 0.0591 - recall: 0.9880 - val_loss: 2.4521e-06 - val_fn: 11.0000 - val_fp: 317.0000 - val_tn: 56569.0000 - val_tp: 64.0000 - val_precision: 0.1680 - val_recall: 0.8533\n",
      "Epoch 17/30\n",
      "227846/227846 - 3s - loss: 7.4886e-07 - fn: 12.0000 - fp: 6914.0000 - tn: 220515.0000 - tp: 405.0000 - precision: 0.0553 - recall: 0.9712 - val_loss: 3.2737e-06 - val_fn: 8.0000 - val_fp: 409.0000 - val_tn: 56477.0000 - val_tp: 67.0000 - val_precision: 0.1408 - val_recall: 0.8933\n",
      "Epoch 18/30\n",
      "227846/227846 - 4s - loss: 4.9367e-07 - fn: 8.0000 - fp: 5201.0000 - tn: 222228.0000 - tp: 409.0000 - precision: 0.0729 - recall: 0.9808 - val_loss: 2.9056e-06 - val_fn: 11.0000 - val_fp: 558.0000 - val_tn: 56328.0000 - val_tp: 64.0000 - val_precision: 0.1029 - val_recall: 0.8533\n",
      "Epoch 19/30\n",
      "227846/227846 - 3s - loss: 5.3547e-07 - fn: 8.0000 - fp: 6676.0000 - tn: 220753.0000 - tp: 409.0000 - precision: 0.0577 - recall: 0.9808 - val_loss: 2.3295e-06 - val_fn: 8.0000 - val_fp: 1570.0000 - val_tn: 55316.0000 - val_tp: 67.0000 - val_precision: 0.0409 - val_recall: 0.8933\n",
      "Epoch 20/30\n",
      "227846/227846 - 3s - loss: 4.2313e-07 - fn: 5.0000 - fp: 4548.0000 - tn: 222881.0000 - tp: 412.0000 - precision: 0.0831 - recall: 0.9880 - val_loss: 2.7761e-06 - val_fn: 8.0000 - val_fp: 486.0000 - val_tn: 56400.0000 - val_tp: 67.0000 - val_precision: 0.1212 - val_recall: 0.8933\n",
      "Epoch 21/30\n",
      "227846/227846 - 4s - loss: 2.6339e-07 - fn: 2.0000 - fp: 2850.0000 - tn: 224579.0000 - tp: 415.0000 - precision: 0.1271 - recall: 0.9952 - val_loss: 4.7658e-06 - val_fn: 10.0000 - val_fp: 200.0000 - val_tn: 56686.0000 - val_tp: 65.0000 - val_precision: 0.2453 - val_recall: 0.8667\n",
      "Epoch 22/30\n",
      "227846/227846 - 4s - loss: 3.4063e-07 - fn: 4.0000 - fp: 3600.0000 - tn: 223829.0000 - tp: 413.0000 - precision: 0.1029 - recall: 0.9904 - val_loss: 3.5020e-06 - val_fn: 9.0000 - val_fp: 408.0000 - val_tn: 56478.0000 - val_tp: 66.0000 - val_precision: 0.1392 - val_recall: 0.8800\n",
      "Epoch 23/30\n",
      "227846/227846 - 4s - loss: 6.6761e-07 - fn: 5.0000 - fp: 7733.0000 - tn: 219696.0000 - tp: 412.0000 - precision: 0.0506 - recall: 0.9880 - val_loss: 3.0039e-06 - val_fn: 8.0000 - val_fp: 741.0000 - val_tn: 56145.0000 - val_tp: 67.0000 - val_precision: 0.0829 - val_recall: 0.8933\n",
      "Epoch 24/30\n",
      "227846/227846 - 4s - loss: 8.9896e-07 - fn: 13.0000 - fp: 6580.0000 - tn: 220849.0000 - tp: 404.0000 - precision: 0.0578 - recall: 0.9688 - val_loss: 1.8068e-06 - val_fn: 7.0000 - val_fp: 672.0000 - val_tn: 56214.0000 - val_tp: 68.0000 - val_precision: 0.0919 - val_recall: 0.9067\n",
      "Epoch 25/30\n",
      "227846/227846 - 3s - loss: 6.2019e-07 - fn: 6.0000 - fp: 4685.0000 - tn: 222744.0000 - tp: 411.0000 - precision: 0.0807 - recall: 0.9856 - val_loss: 4.3467e-06 - val_fn: 14.0000 - val_fp: 103.0000 - val_tn: 56783.0000 - val_tp: 61.0000 - val_precision: 0.3720 - val_recall: 0.8133\n",
      "Epoch 26/30\n",
      "227846/227846 - 3s - loss: 5.7750e-07 - fn: 7.0000 - fp: 4484.0000 - tn: 222945.0000 - tp: 410.0000 - precision: 0.0838 - recall: 0.9832 - val_loss: 2.6415e-06 - val_fn: 8.0000 - val_fp: 1131.0000 - val_tn: 55755.0000 - val_tp: 67.0000 - val_precision: 0.0559 - val_recall: 0.8933\n",
      "Epoch 27/30\n",
      "227846/227846 - 3s - loss: 6.4383e-07 - fn: 8.0000 - fp: 5272.0000 - tn: 222157.0000 - tp: 409.0000 - precision: 0.0720 - recall: 0.9808 - val_loss: 2.7732e-06 - val_fn: 9.0000 - val_fp: 482.0000 - val_tn: 56404.0000 - val_tp: 66.0000 - val_precision: 0.1204 - val_recall: 0.8800\n",
      "Epoch 28/30\n",
      "227846/227846 - 4s - loss: 4.5588e-07 - fn: 2.0000 - fp: 2878.0000 - tn: 224551.0000 - tp: 415.0000 - precision: 0.1260 - recall: 0.9952 - val_loss: 6.5349e-06 - val_fn: 15.0000 - val_fp: 279.0000 - val_tn: 56607.0000 - val_tp: 60.0000 - val_precision: 0.1770 - val_recall: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "227846/227846 - 3s - loss: 7.4961e-07 - fn: 4.0000 - fp: 4304.0000 - tn: 223125.0000 - tp: 413.0000 - precision: 0.0876 - recall: 0.9904 - val_loss: 3.6293e-06 - val_fn: 10.0000 - val_fp: 333.0000 - val_tn: 56553.0000 - val_tp: 65.0000 - val_precision: 0.1633 - val_recall: 0.8667\n",
      "Epoch 30/30\n",
      "227846/227846 - 3s - loss: 7.4515e-07 - fn: 5.0000 - fp: 4714.0000 - tn: 222715.0000 - tp: 412.0000 - precision: 0.0804 - recall: 0.9880 - val_loss: 2.5592e-06 - val_fn: 7.0000 - val_fp: 627.0000 - val_tn: 56259.0000 - val_tp: 68.0000 - val_precision: 0.0978 - val_recall: 0.9067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fa31486b08>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "model.fit(\n",
    "    train_features,\n",
    "    train_targets,\n",
    "    batch_size=2048,\n",
    "    epochs=30,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(val_features, val_targets),\n",
    "    class_weight=class_weight,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful resources:\n",
    "- https://keras.io/examples/structured_data/imbalanced_classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
